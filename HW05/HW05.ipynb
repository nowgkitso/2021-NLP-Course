{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP_HW5",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3b-Dt-DG8HOu",
        "outputId": "e700c6ec-8fbc-4589-c762-395e02d18a00"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_3XsGA7485eI"
      },
      "source": [
        "import json\n",
        "from tensorflow.keras import optimizers\n",
        "import numpy as np\n",
        "\n",
        "data = []\n",
        "en_data = []\n",
        "ch_data = []\n",
        "\n",
        "def extract(string):\n",
        "    for ch in string :\n",
        "        if u'\\u4e00' <= ch <= u'\\u9fff':\n",
        "            return True\n",
        "    return False\n",
        "\n",
        "for line in open('/content/drive/MyDrive/Colab Notebooks/translation2019zh_train.json', 'r', encoding='utf-8'):\n",
        "    data.append(json.loads(line))  \n",
        "\n",
        "\n",
        "for i in range(len(data)):\n",
        "    if extract(data[i]['chinese']) == True :\n",
        "        if len(data[i]['chinese']) < 10:\n",
        "            en_data.append(data[i]['english'])\n",
        "            ch_data.append('\\t'+data[i]['chinese']+'。')\n",
        "        if len(ch_data) == 100 :\n",
        "            break\n",
        "data = []"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0YrAfS1s9pA5"
      },
      "source": [
        "en_vocab = set(''.join(en_data))\n",
        "id2en = list(en_vocab)\n",
        "en2id = {c:i for i,c in enumerate(id2en)}\n",
        "\n",
        "# 分別生成中英文字典\n",
        "ch_vocab = set(''.join(ch_data))\n",
        "id2ch = list(ch_vocab)\n",
        "ch2id = {c:i for i,c in enumerate(id2ch)}"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vlgsWRW391V3",
        "outputId": "cf593210-3281-4ffd-a1d4-9eab01eff82f"
      },
      "source": [
        "for i in range(10):\n",
        "  print(en_data[i],\"\\n\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Look at these coasters over here. \n",
            "\n",
            "Choose a recorder. \n",
            "\n",
            "I hadn't paid the telephone bill. \n",
            "\n",
            "That's easier said than done, of course. \n",
            "\n",
            "Side-to-Side Movements. \n",
            "\n",
            "about like 80 degrees. \n",
            "\n",
            "We all are from Shandong. \n",
            "\n",
            "She was possessed by a devil. \n",
            "\n",
            "This wool knits up well. \n",
            "\n",
            "The majority was wrong last time. \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rOwZiP8I93MI"
      },
      "source": [
        "en_num_data = [[en2id[en] for en in line ] for line in en_data]\n",
        "ch_num_data = [[ch2id[ch] for ch in line] for line in ch_data]\n",
        "de_num_data = [[ch2id[ch] for ch in line][1:] for line in ch_data]\n",
        "data = []"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EJ9FvNI_-AOw",
        "outputId": "c1381ccc-b386-4e85-8a8e-9243de2ef62e"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# 獲取輸入輸出端的最大長度\n",
        "max_encoder_seq_length = max([len(txt) for txt in en_num_data])\n",
        "max_decoder_seq_length = max([len(txt) for txt in ch_num_data])\n",
        "print('max encoder length:', max_encoder_seq_length)\n",
        "print('max decoder length:', max_decoder_seq_length)\n",
        "\n",
        "# 將數據進行onehot處理\n",
        "encoder_input_data = np.zeros((len(en_num_data), max_encoder_seq_length, len(en2id)), dtype='float32')\n",
        "decoder_input_data = np.zeros((len(ch_num_data), max_decoder_seq_length, len(ch2id)), dtype='float32')\n",
        "decoder_target_data = np.zeros((len(ch_num_data), max_decoder_seq_length, len(ch2id)), dtype='float32')\n",
        "\n",
        "for i in range(len(ch_num_data)):\n",
        "    for t, j in enumerate(en_num_data[i]):\n",
        "        encoder_input_data[i, t, j] = 1.\n",
        "    for t, j in enumerate(ch_num_data[i]):\n",
        "        decoder_input_data[i, t, j] = 1.\n",
        "    for t, j in enumerate(de_num_data[i]):\n",
        "        decoder_target_data[i, t, j] = 1."
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "max encoder length: 49\n",
            "max decoder length: 11\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p1uIpioC-BtI"
      },
      "source": [
        "# =======預定義模型參數========\n",
        "EN_VOCAB_SIZE = len(en2id)\n",
        "CH_VOCAB_SIZE = len(ch2id)\n",
        "HIDDEN_SIZE = 256\n",
        "\n",
        "LEARNING_RATE = 0.001\n",
        "BATCH_SIZE = 10\n",
        "EPOCHS = 600"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xFQysNHO-EJA"
      },
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Input, LSTM, Dense, Embedding\n",
        "from tensorflow.keras.optimizers import Adam \n",
        "import numpy as np\n",
        "\n",
        "# ==============encoder=============\n",
        "encoder_inputs = Input(shape=(None, EN_VOCAB_SIZE))\n",
        "#emb_inp = Embedding(output_dim=HIDDEN_SIZE, input_dim=EN_VOCAB_SIZE)(encoder_inputs)\n",
        "encoder_h1, encoder_state_h1, encoder_state_c1 = LSTM(HIDDEN_SIZE, return_sequences=True, return_state=True)(encoder_inputs)\n",
        "encoder_h2, encoder_state_h2, encoder_state_c2 = LSTM(HIDDEN_SIZE, return_state=True)(encoder_h1)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FyBx48Jy-H4A"
      },
      "source": [
        "# ==============decoder=============\n",
        "decoder_inputs = Input(shape=(None, CH_VOCAB_SIZE))\n",
        "\n",
        "#emb_target = Embedding(output_dim=HIDDEN_SIZE, input_dim=CH_VOCAB_SIZE, mask_zero=True)(decoder_inputs)\n",
        "lstm1 = LSTM(HIDDEN_SIZE, return_sequences=True, return_state=True)\n",
        "lstm2 = LSTM(HIDDEN_SIZE, return_sequences=True, return_state=True)\n",
        "decoder_dense = Dense(CH_VOCAB_SIZE, activation='softmax')\n",
        "\n",
        "decoder_h1, _, _ = lstm1(decoder_inputs, initial_state=[encoder_state_h1, encoder_state_c1])\n",
        "decoder_h2, _, _ = lstm2(decoder_h1, initial_state=[encoder_state_h2, encoder_state_c2])\n",
        "decoder_outputs = decoder_dense(decoder_h2)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rJtqeSFD-KU4",
        "outputId": "2c41864c-9346-4738-816f-e0afb1f63929"
      },
      "source": [
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "opt = Adam(lr=LEARNING_RATE, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
        "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()\n",
        "model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          validation_split=0.)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, None, 66)]   0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, None, 403)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     [(None, None, 256),  330752      input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm_2 (LSTM)                   [(None, None, 256),  675840      input_2[0][0]                    \n",
            "                                                                 lstm[0][1]                       \n",
            "                                                                 lstm[0][2]                       \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   [(None, 256), (None, 525312      lstm[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "lstm_3 (LSTM)                   [(None, None, 256),  525312      lstm_2[0][0]                     \n",
            "                                                                 lstm_1[0][1]                     \n",
            "                                                                 lstm_1[0][2]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, None, 403)    103571      lstm_3[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 2,160,787\n",
            "Trainable params: 2,160,787\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/300\n",
            "10/10 [==============================] - 10s 62ms/step - loss: 4.4699 - accuracy: 0.1455\n",
            "Epoch 2/300\n",
            "10/10 [==============================] - 1s 61ms/step - loss: 4.0049 - accuracy: 0.1736\n",
            "Epoch 3/300\n",
            "10/10 [==============================] - 1s 61ms/step - loss: 3.8657 - accuracy: 0.1736\n",
            "Epoch 4/300\n",
            "10/10 [==============================] - 1s 61ms/step - loss: 3.7775 - accuracy: 0.1736\n",
            "Epoch 5/300\n",
            "10/10 [==============================] - 1s 61ms/step - loss: 3.7221 - accuracy: 0.1818\n",
            "Epoch 6/300\n",
            "10/10 [==============================] - 1s 60ms/step - loss: 3.6680 - accuracy: 0.1782\n",
            "Epoch 7/300\n",
            "10/10 [==============================] - 1s 61ms/step - loss: 3.6455 - accuracy: 0.1809\n",
            "Epoch 8/300\n",
            "10/10 [==============================] - 1s 61ms/step - loss: 3.5954 - accuracy: 0.1836\n",
            "Epoch 9/300\n",
            "10/10 [==============================] - 1s 61ms/step - loss: 3.5559 - accuracy: 0.1800\n",
            "Epoch 10/300\n",
            "10/10 [==============================] - 1s 61ms/step - loss: 3.5431 - accuracy: 0.1818\n",
            "Epoch 11/300\n",
            "10/10 [==============================] - 1s 61ms/step - loss: 3.5113 - accuracy: 0.1845\n",
            "Epoch 12/300\n",
            "10/10 [==============================] - 1s 61ms/step - loss: 3.4785 - accuracy: 0.1827\n",
            "Epoch 13/300\n",
            "10/10 [==============================] - 1s 63ms/step - loss: 3.4603 - accuracy: 0.1827\n",
            "Epoch 14/300\n",
            "10/10 [==============================] - 1s 60ms/step - loss: 3.4141 - accuracy: 0.1873\n",
            "Epoch 15/300\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 3.3979 - accuracy: 0.1873\n",
            "Epoch 16/300\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 3.3690 - accuracy: 0.1864\n",
            "Epoch 17/300\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 3.3381 - accuracy: 0.1900\n",
            "Epoch 18/300\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 3.2973 - accuracy: 0.1882\n",
            "Epoch 19/300\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 3.2861 - accuracy: 0.1900\n",
            "Epoch 20/300\n",
            "10/10 [==============================] - 1s 60ms/step - loss: 3.2616 - accuracy: 0.1927\n",
            "Epoch 21/300\n",
            "10/10 [==============================] - 1s 57ms/step - loss: 3.2226 - accuracy: 0.1964\n",
            "Epoch 22/300\n",
            "10/10 [==============================] - 1s 57ms/step - loss: 3.1851 - accuracy: 0.1945\n",
            "Epoch 23/300\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 3.1373 - accuracy: 0.1936\n",
            "Epoch 24/300\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 3.1103 - accuracy: 0.1945\n",
            "Epoch 25/300\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 3.0828 - accuracy: 0.1991\n",
            "Epoch 26/300\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 3.0419 - accuracy: 0.1927\n",
            "Epoch 27/300\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 3.0223 - accuracy: 0.1973\n",
            "Epoch 28/300\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 2.9742 - accuracy: 0.1973\n",
            "Epoch 29/300\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 2.9252 - accuracy: 0.1982\n",
            "Epoch 30/300\n",
            "10/10 [==============================] - 1s 57ms/step - loss: 2.8969 - accuracy: 0.2064\n",
            "Epoch 31/300\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 2.8501 - accuracy: 0.2045\n",
            "Epoch 32/300\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 2.8088 - accuracy: 0.2136\n",
            "Epoch 33/300\n",
            "10/10 [==============================] - 1s 60ms/step - loss: 2.7713 - accuracy: 0.2100\n",
            "Epoch 34/300\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 2.7515 - accuracy: 0.2118\n",
            "Epoch 35/300\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 2.7135 - accuracy: 0.2264\n",
            "Epoch 36/300\n",
            "10/10 [==============================] - 1s 57ms/step - loss: 2.6586 - accuracy: 0.2264\n",
            "Epoch 37/300\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 2.5911 - accuracy: 0.2455\n",
            "Epoch 38/300\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 2.5439 - accuracy: 0.2500\n",
            "Epoch 39/300\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 2.5101 - accuracy: 0.2582\n",
            "Epoch 40/300\n",
            "10/10 [==============================] - 1s 61ms/step - loss: 2.4833 - accuracy: 0.2718\n",
            "Epoch 41/300\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 2.5247 - accuracy: 0.2591\n",
            "Epoch 42/300\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 2.5155 - accuracy: 0.2727\n",
            "Epoch 43/300\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 2.4144 - accuracy: 0.2864\n",
            "Epoch 44/300\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 2.3086 - accuracy: 0.3255\n",
            "Epoch 45/300\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 2.2333 - accuracy: 0.3300\n",
            "Epoch 46/300\n",
            "10/10 [==============================] - 1s 60ms/step - loss: 2.1967 - accuracy: 0.3527\n",
            "Epoch 47/300\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 2.1279 - accuracy: 0.3764\n",
            "Epoch 48/300\n",
            "10/10 [==============================] - 1s 60ms/step - loss: 2.0556 - accuracy: 0.3955\n",
            "Epoch 49/300\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 1.9908 - accuracy: 0.4082\n",
            "Epoch 50/300\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 1.9245 - accuracy: 0.4245\n",
            "Epoch 51/300\n",
            "10/10 [==============================] - 1s 60ms/step - loss: 1.8713 - accuracy: 0.4355\n",
            "Epoch 52/300\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 1.8073 - accuracy: 0.4573\n",
            "Epoch 53/300\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 1.7550 - accuracy: 0.4718\n",
            "Epoch 54/300\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 1.9144 - accuracy: 0.4527\n",
            "Epoch 55/300\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 1.9801 - accuracy: 0.4455\n",
            "Epoch 56/300\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 1.7560 - accuracy: 0.4745\n",
            "Epoch 57/300\n",
            "10/10 [==============================] - 1s 60ms/step - loss: 1.6475 - accuracy: 0.4918\n",
            "Epoch 58/300\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 1.5656 - accuracy: 0.5127\n",
            "Epoch 59/300\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 1.5191 - accuracy: 0.5300\n",
            "Epoch 60/300\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 1.4546 - accuracy: 0.5373\n",
            "Epoch 61/300\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 1.4095 - accuracy: 0.5427\n",
            "Epoch 62/300\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 1.3778 - accuracy: 0.5527\n",
            "Epoch 63/300\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 1.3402 - accuracy: 0.5582\n",
            "Epoch 64/300\n",
            "10/10 [==============================] - 1s 60ms/step - loss: 1.3084 - accuracy: 0.5573\n",
            "Epoch 65/300\n",
            "10/10 [==============================] - 1s 60ms/step - loss: 1.2879 - accuracy: 0.5700\n",
            "Epoch 66/300\n",
            "10/10 [==============================] - 1s 60ms/step - loss: 1.2587 - accuracy: 0.5673\n",
            "Epoch 67/300\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 1.2217 - accuracy: 0.5700\n",
            "Epoch 68/300\n",
            "10/10 [==============================] - 1s 60ms/step - loss: 1.1821 - accuracy: 0.5873\n",
            "Epoch 69/300\n",
            "10/10 [==============================] - 1s 60ms/step - loss: 1.1639 - accuracy: 0.5809\n",
            "Epoch 70/300\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 1.1528 - accuracy: 0.5845\n",
            "Epoch 71/300\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 1.1701 - accuracy: 0.5827\n",
            "Epoch 72/300\n",
            "10/10 [==============================] - 1s 60ms/step - loss: 1.0967 - accuracy: 0.5945\n",
            "Epoch 73/300\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 1.0495 - accuracy: 0.6018\n",
            "Epoch 74/300\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 1.0060 - accuracy: 0.6182\n",
            "Epoch 75/300\n",
            "10/10 [==============================] - 1s 60ms/step - loss: 0.9705 - accuracy: 0.6245\n",
            "Epoch 76/300\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.9413 - accuracy: 0.6236\n",
            "Epoch 77/300\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.9180 - accuracy: 0.6255\n",
            "Epoch 78/300\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 0.9077 - accuracy: 0.6327\n",
            "Epoch 79/300\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.9281 - accuracy: 0.6291\n",
            "Epoch 80/300\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.9624 - accuracy: 0.6155\n",
            "Epoch 81/300\n",
            "10/10 [==============================] - 1s 60ms/step - loss: 0.9748 - accuracy: 0.6136\n",
            "Epoch 82/300\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 0.9217 - accuracy: 0.6282\n",
            "Epoch 83/300\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 0.8756 - accuracy: 0.6418\n",
            "Epoch 84/300\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.8383 - accuracy: 0.6491\n",
            "Epoch 85/300\n",
            "10/10 [==============================] - 1s 57ms/step - loss: 0.8029 - accuracy: 0.6509\n",
            "Epoch 86/300\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 0.7705 - accuracy: 0.6582\n",
            "Epoch 87/300\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.7493 - accuracy: 0.6664\n",
            "Epoch 88/300\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.7312 - accuracy: 0.6655\n",
            "Epoch 89/300\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.7119 - accuracy: 0.6700\n",
            "Epoch 90/300\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.6980 - accuracy: 0.6736\n",
            "Epoch 91/300\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 0.6841 - accuracy: 0.6764\n",
            "Epoch 92/300\n",
            "10/10 [==============================] - 1s 57ms/step - loss: 0.6657 - accuracy: 0.6791\n",
            "Epoch 93/300\n",
            "10/10 [==============================] - 1s 57ms/step - loss: 0.6530 - accuracy: 0.6818\n",
            "Epoch 94/300\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 0.6364 - accuracy: 0.6845\n",
            "Epoch 95/300\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 0.6219 - accuracy: 0.6873\n",
            "Epoch 96/300\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 0.6059 - accuracy: 0.6891\n",
            "Epoch 97/300\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.6063 - accuracy: 0.6909\n",
            "Epoch 98/300\n",
            "10/10 [==============================] - 1s 57ms/step - loss: 0.6210 - accuracy: 0.6864\n",
            "Epoch 99/300\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 0.6072 - accuracy: 0.6918\n",
            "Epoch 100/300\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 0.5904 - accuracy: 0.6964\n",
            "Epoch 101/300\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.6003 - accuracy: 0.6882\n",
            "Epoch 102/300\n",
            "10/10 [==============================] - 1s 61ms/step - loss: 0.5863 - accuracy: 0.6936\n",
            "Epoch 103/300\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 0.5758 - accuracy: 0.6982\n",
            "Epoch 104/300\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.5945 - accuracy: 0.6864\n",
            "Epoch 105/300\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 0.5832 - accuracy: 0.6891\n",
            "Epoch 106/300\n",
            "10/10 [==============================] - 1s 57ms/step - loss: 0.5540 - accuracy: 0.6936\n",
            "Epoch 107/300\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 0.5322 - accuracy: 0.6964\n",
            "Epoch 108/300\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.5183 - accuracy: 0.7000\n",
            "Epoch 109/300\n",
            "10/10 [==============================] - 1s 57ms/step - loss: 0.4957 - accuracy: 0.7027\n",
            "Epoch 110/300\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 0.4753 - accuracy: 0.7036\n",
            "Epoch 111/300\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 0.4545 - accuracy: 0.7127\n",
            "Epoch 112/300\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.4367 - accuracy: 0.7136\n",
            "Epoch 113/300\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 0.4245 - accuracy: 0.7173\n",
            "Epoch 114/300\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 0.4149 - accuracy: 0.7145\n",
            "Epoch 115/300\n",
            "10/10 [==============================] - 1s 57ms/step - loss: 0.4056 - accuracy: 0.7145\n",
            "Epoch 116/300\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 0.3964 - accuracy: 0.7173\n",
            "Epoch 117/300\n",
            "10/10 [==============================] - 1s 57ms/step - loss: 0.3788 - accuracy: 0.7164\n",
            "Epoch 118/300\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.3729 - accuracy: 0.7173\n",
            "Epoch 119/300\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 0.3594 - accuracy: 0.7245\n",
            "Epoch 120/300\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.3472 - accuracy: 0.7309\n",
            "Epoch 121/300\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 0.3438 - accuracy: 0.7309\n",
            "Epoch 122/300\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.3333 - accuracy: 0.7373\n",
            "Epoch 123/300\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 0.3252 - accuracy: 0.7382\n",
            "Epoch 124/300\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 0.3464 - accuracy: 0.7255\n",
            "Epoch 125/300\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 0.4496 - accuracy: 0.7009\n",
            "Epoch 126/300\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 0.5579 - accuracy: 0.6827\n",
            "Epoch 127/300\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 0.4965 - accuracy: 0.6973\n",
            "Epoch 128/300\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 0.4286 - accuracy: 0.7082\n",
            "Epoch 129/300\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.3818 - accuracy: 0.7209\n",
            "Epoch 130/300\n",
            "10/10 [==============================] - 1s 57ms/step - loss: 0.3323 - accuracy: 0.7318\n",
            "Epoch 131/300\n",
            "10/10 [==============================] - 1s 57ms/step - loss: 0.3020 - accuracy: 0.7382\n",
            "Epoch 132/300\n",
            "10/10 [==============================] - 1s 60ms/step - loss: 0.2763 - accuracy: 0.7482\n",
            "Epoch 133/300\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.2572 - accuracy: 0.7500\n",
            "Epoch 134/300\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 0.2422 - accuracy: 0.7555\n",
            "Epoch 135/300\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.2383 - accuracy: 0.7564\n",
            "Epoch 136/300\n",
            "10/10 [==============================] - 1s 57ms/step - loss: 0.2330 - accuracy: 0.7518\n",
            "Epoch 137/300\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 0.2205 - accuracy: 0.7582\n",
            "Epoch 138/300\n",
            "10/10 [==============================] - 1s 57ms/step - loss: 0.2101 - accuracy: 0.7527\n",
            "Epoch 139/300\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.1956 - accuracy: 0.7664\n",
            "Epoch 140/300\n",
            "10/10 [==============================] - 1s 56ms/step - loss: 0.1866 - accuracy: 0.7718\n",
            "Epoch 141/300\n",
            "10/10 [==============================] - 1s 57ms/step - loss: 0.1862 - accuracy: 0.7664\n",
            "Epoch 142/300\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.1931 - accuracy: 0.7627\n",
            "Epoch 143/300\n",
            "10/10 [==============================] - 1s 56ms/step - loss: 0.1941 - accuracy: 0.7645\n",
            "Epoch 144/300\n",
            "10/10 [==============================] - 1s 57ms/step - loss: 0.1853 - accuracy: 0.7655\n",
            "Epoch 145/300\n",
            "10/10 [==============================] - 1s 55ms/step - loss: 0.1891 - accuracy: 0.7645\n",
            "Epoch 146/300\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 0.1736 - accuracy: 0.7745\n",
            "Epoch 147/300\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 0.1675 - accuracy: 0.7718\n",
            "Epoch 148/300\n",
            "10/10 [==============================] - 1s 56ms/step - loss: 0.1637 - accuracy: 0.7691\n",
            "Epoch 149/300\n",
            "10/10 [==============================] - 1s 57ms/step - loss: 0.1556 - accuracy: 0.7718\n",
            "Epoch 150/300\n",
            "10/10 [==============================] - 1s 56ms/step - loss: 0.1475 - accuracy: 0.7773\n",
            "Epoch 151/300\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 0.1415 - accuracy: 0.7800\n",
            "Epoch 152/300\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 0.1369 - accuracy: 0.7773\n",
            "Epoch 153/300\n",
            "10/10 [==============================] - 1s 56ms/step - loss: 0.1262 - accuracy: 0.7818\n",
            "Epoch 154/300\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 0.1165 - accuracy: 0.7836\n",
            "Epoch 155/300\n",
            "10/10 [==============================] - 1s 55ms/step - loss: 0.1092 - accuracy: 0.7873\n",
            "Epoch 156/300\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 0.1037 - accuracy: 0.7900\n",
            "Epoch 157/300\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.0961 - accuracy: 0.7891\n",
            "Epoch 158/300\n",
            "10/10 [==============================] - 1s 57ms/step - loss: 0.0925 - accuracy: 0.7918\n",
            "Epoch 159/300\n",
            "10/10 [==============================] - 1s 56ms/step - loss: 0.0887 - accuracy: 0.7909\n",
            "Epoch 160/300\n",
            "10/10 [==============================] - 1s 57ms/step - loss: 0.0854 - accuracy: 0.7918\n",
            "Epoch 161/300\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 0.0809 - accuracy: 0.7918\n",
            "Epoch 162/300\n",
            "10/10 [==============================] - 1s 56ms/step - loss: 0.0775 - accuracy: 0.7927\n",
            "Epoch 163/300\n",
            "10/10 [==============================] - 1s 57ms/step - loss: 0.0742 - accuracy: 0.7909\n",
            "Epoch 164/300\n",
            "10/10 [==============================] - 1s 55ms/step - loss: 0.0711 - accuracy: 0.7936\n",
            "Epoch 165/300\n",
            "10/10 [==============================] - 1s 56ms/step - loss: 0.0687 - accuracy: 0.7909\n",
            "Epoch 166/300\n",
            "10/10 [==============================] - 1s 55ms/step - loss: 0.0668 - accuracy: 0.7936\n",
            "Epoch 167/300\n",
            "10/10 [==============================] - 1s 56ms/step - loss: 0.0646 - accuracy: 0.7927\n",
            "Epoch 168/300\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 0.0616 - accuracy: 0.7927\n",
            "Epoch 169/300\n",
            "10/10 [==============================] - 1s 56ms/step - loss: 0.0591 - accuracy: 0.7927\n",
            "Epoch 170/300\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.0578 - accuracy: 0.7936\n",
            "Epoch 171/300\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 0.0554 - accuracy: 0.7927\n",
            "Epoch 172/300\n",
            "10/10 [==============================] - 1s 55ms/step - loss: 0.0564 - accuracy: 0.7936\n",
            "Epoch 173/300\n",
            "10/10 [==============================] - 1s 55ms/step - loss: 0.0548 - accuracy: 0.7918\n",
            "Epoch 174/300\n",
            "10/10 [==============================] - 1s 55ms/step - loss: 0.0535 - accuracy: 0.7918\n",
            "Epoch 175/300\n",
            "10/10 [==============================] - 1s 55ms/step - loss: 0.0561 - accuracy: 0.7936\n",
            "Epoch 176/300\n",
            "10/10 [==============================] - 1s 55ms/step - loss: 0.0511 - accuracy: 0.7936\n",
            "Epoch 177/300\n",
            "10/10 [==============================] - 1s 56ms/step - loss: 0.0493 - accuracy: 0.7936\n",
            "Epoch 178/300\n",
            "10/10 [==============================] - 1s 57ms/step - loss: 0.0476 - accuracy: 0.7936\n",
            "Epoch 179/300\n",
            "10/10 [==============================] - 1s 56ms/step - loss: 0.0452 - accuracy: 0.7936\n",
            "Epoch 180/300\n",
            "10/10 [==============================] - 1s 56ms/step - loss: 0.0448 - accuracy: 0.7936\n",
            "Epoch 181/300\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 0.0432 - accuracy: 0.7927\n",
            "Epoch 182/300\n",
            "10/10 [==============================] - 1s 55ms/step - loss: 0.0430 - accuracy: 0.7936\n",
            "Epoch 183/300\n",
            "10/10 [==============================] - 1s 57ms/step - loss: 0.0433 - accuracy: 0.7927\n",
            "Epoch 184/300\n",
            "10/10 [==============================] - 1s 55ms/step - loss: 0.0428 - accuracy: 0.7936\n",
            "Epoch 185/300\n",
            "10/10 [==============================] - 1s 55ms/step - loss: 0.0419 - accuracy: 0.7927\n",
            "Epoch 186/300\n",
            "10/10 [==============================] - 1s 56ms/step - loss: 0.0403 - accuracy: 0.7936\n",
            "Epoch 187/300\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.0395 - accuracy: 0.7936\n",
            "Epoch 188/300\n",
            "10/10 [==============================] - 1s 56ms/step - loss: 0.0380 - accuracy: 0.7936\n",
            "Epoch 189/300\n",
            "10/10 [==============================] - 1s 55ms/step - loss: 0.0366 - accuracy: 0.7936\n",
            "Epoch 190/300\n",
            "10/10 [==============================] - 1s 56ms/step - loss: 0.0353 - accuracy: 0.7936\n",
            "Epoch 191/300\n",
            "10/10 [==============================] - 1s 57ms/step - loss: 0.0356 - accuracy: 0.7936\n",
            "Epoch 192/300\n",
            "10/10 [==============================] - 1s 55ms/step - loss: 0.0346 - accuracy: 0.7936\n",
            "Epoch 193/300\n",
            "10/10 [==============================] - 1s 57ms/step - loss: 0.0336 - accuracy: 0.7927\n",
            "Epoch 194/300\n",
            "10/10 [==============================] - 1s 56ms/step - loss: 0.0334 - accuracy: 0.7936\n",
            "Epoch 195/300\n",
            "10/10 [==============================] - 1s 52ms/step - loss: 0.0334 - accuracy: 0.7936\n",
            "Epoch 196/300\n",
            "10/10 [==============================] - 1s 55ms/step - loss: 0.0323 - accuracy: 0.7927\n",
            "Epoch 197/300\n",
            "10/10 [==============================] - 1s 55ms/step - loss: 0.0328 - accuracy: 0.7936\n",
            "Epoch 198/300\n",
            "10/10 [==============================] - 1s 56ms/step - loss: 0.0315 - accuracy: 0.7936\n",
            "Epoch 199/300\n",
            "10/10 [==============================] - 1s 55ms/step - loss: 0.0310 - accuracy: 0.7936\n",
            "Epoch 200/300\n",
            "10/10 [==============================] - 1s 55ms/step - loss: 0.0308 - accuracy: 0.7936\n",
            "Epoch 201/300\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.0304 - accuracy: 0.7936\n",
            "Epoch 202/300\n",
            "10/10 [==============================] - 1s 55ms/step - loss: 0.0296 - accuracy: 0.7936\n",
            "Epoch 203/300\n",
            "10/10 [==============================] - 1s 55ms/step - loss: 0.0295 - accuracy: 0.7936\n",
            "Epoch 204/300\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 0.0289 - accuracy: 0.7936\n",
            "Epoch 205/300\n",
            "10/10 [==============================] - 1s 55ms/step - loss: 0.0289 - accuracy: 0.7936\n",
            "Epoch 206/300\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 0.0282 - accuracy: 0.7927\n",
            "Epoch 207/300\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 0.0284 - accuracy: 0.7936\n",
            "Epoch 208/300\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 0.0274 - accuracy: 0.7936\n",
            "Epoch 209/300\n",
            "10/10 [==============================] - 1s 55ms/step - loss: 0.0274 - accuracy: 0.7936\n",
            "Epoch 210/300\n",
            "10/10 [==============================] - 1s 56ms/step - loss: 0.0271 - accuracy: 0.7927\n",
            "Epoch 211/300\n",
            "10/10 [==============================] - 1s 56ms/step - loss: 0.0268 - accuracy: 0.7936\n",
            "Epoch 212/300\n",
            "10/10 [==============================] - 1s 56ms/step - loss: 0.0265 - accuracy: 0.7936\n",
            "Epoch 213/300\n",
            "10/10 [==============================] - 1s 56ms/step - loss: 0.0263 - accuracy: 0.7936\n",
            "Epoch 214/300\n",
            "10/10 [==============================] - 1s 55ms/step - loss: 0.0261 - accuracy: 0.7927\n",
            "Epoch 215/300\n",
            "10/10 [==============================] - 1s 55ms/step - loss: 0.0258 - accuracy: 0.7936\n",
            "Epoch 216/300\n",
            "10/10 [==============================] - 1s 55ms/step - loss: 0.0257 - accuracy: 0.7936\n",
            "Epoch 217/300\n",
            "10/10 [==============================] - 1s 55ms/step - loss: 0.0252 - accuracy: 0.7936\n",
            "Epoch 218/300\n",
            "10/10 [==============================] - 1s 56ms/step - loss: 0.0252 - accuracy: 0.7927\n",
            "Epoch 219/300\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 0.0246 - accuracy: 0.7936\n",
            "Epoch 220/300\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 0.0246 - accuracy: 0.7927\n",
            "Epoch 221/300\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.0253 - accuracy: 0.7936\n",
            "Epoch 222/300\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 0.0243 - accuracy: 0.7927\n",
            "Epoch 223/300\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 0.0248 - accuracy: 0.7936\n",
            "Epoch 224/300\n",
            "10/10 [==============================] - 1s 55ms/step - loss: 0.0246 - accuracy: 0.7927\n",
            "Epoch 225/300\n",
            "10/10 [==============================] - 1s 52ms/step - loss: 0.0257 - accuracy: 0.7936\n",
            "Epoch 226/300\n",
            "10/10 [==============================] - 1s 52ms/step - loss: 0.0848 - accuracy: 0.7782\n",
            "Epoch 227/300\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.3834 - accuracy: 0.7009\n",
            "Epoch 228/300\n",
            "10/10 [==============================] - 1s 55ms/step - loss: 0.6662 - accuracy: 0.6409\n",
            "Epoch 229/300\n",
            "10/10 [==============================] - 1s 55ms/step - loss: 0.6144 - accuracy: 0.6536\n",
            "Epoch 230/300\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 0.4558 - accuracy: 0.6955\n",
            "Epoch 231/300\n",
            "10/10 [==============================] - 1s 51ms/step - loss: 0.3368 - accuracy: 0.7164\n",
            "Epoch 232/300\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 0.2545 - accuracy: 0.7391\n",
            "Epoch 233/300\n",
            "10/10 [==============================] - 1s 51ms/step - loss: 0.2166 - accuracy: 0.7518\n",
            "Epoch 234/300\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.1684 - accuracy: 0.7645\n",
            "Epoch 235/300\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.1558 - accuracy: 0.7655\n",
            "Epoch 236/300\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.1217 - accuracy: 0.7718\n",
            "Epoch 237/300\n",
            "10/10 [==============================] - 1s 52ms/step - loss: 0.1192 - accuracy: 0.7745\n",
            "Epoch 238/300\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.0981 - accuracy: 0.7800\n",
            "Epoch 239/300\n",
            "10/10 [==============================] - 1s 51ms/step - loss: 0.0864 - accuracy: 0.7818\n",
            "Epoch 240/300\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 0.0792 - accuracy: 0.7845\n",
            "Epoch 241/300\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.0798 - accuracy: 0.7791\n",
            "Epoch 242/300\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.0984 - accuracy: 0.7755\n",
            "Epoch 243/300\n",
            "10/10 [==============================] - 1s 51ms/step - loss: 0.0833 - accuracy: 0.7809\n",
            "Epoch 244/300\n",
            "10/10 [==============================] - 1s 52ms/step - loss: 0.0622 - accuracy: 0.7855\n",
            "Epoch 245/300\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.0523 - accuracy: 0.7909\n",
            "Epoch 246/300\n",
            "10/10 [==============================] - 1s 55ms/step - loss: 0.0442 - accuracy: 0.7936\n",
            "Epoch 247/300\n",
            "10/10 [==============================] - 1s 52ms/step - loss: 0.0408 - accuracy: 0.7936\n",
            "Epoch 248/300\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 0.0411 - accuracy: 0.7927\n",
            "Epoch 249/300\n",
            "10/10 [==============================] - 1s 52ms/step - loss: 0.0535 - accuracy: 0.7900\n",
            "Epoch 250/300\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.0576 - accuracy: 0.7873\n",
            "Epoch 251/300\n",
            "10/10 [==============================] - 1s 52ms/step - loss: 0.0878 - accuracy: 0.7764\n",
            "Epoch 252/300\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.0855 - accuracy: 0.7791\n",
            "Epoch 253/300\n",
            "10/10 [==============================] - 1s 50ms/step - loss: 0.0765 - accuracy: 0.7836\n",
            "Epoch 254/300\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.0575 - accuracy: 0.7900\n",
            "Epoch 255/300\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.0501 - accuracy: 0.7909\n",
            "Epoch 256/300\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.0417 - accuracy: 0.7918\n",
            "Epoch 257/300\n",
            "10/10 [==============================] - 1s 52ms/step - loss: 0.0458 - accuracy: 0.7927\n",
            "Epoch 258/300\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.0338 - accuracy: 0.7936\n",
            "Epoch 259/300\n",
            "10/10 [==============================] - 1s 51ms/step - loss: 0.0306 - accuracy: 0.7936\n",
            "Epoch 260/300\n",
            "10/10 [==============================] - 1s 51ms/step - loss: 0.0277 - accuracy: 0.7936\n",
            "Epoch 261/300\n",
            "10/10 [==============================] - 1s 51ms/step - loss: 0.0261 - accuracy: 0.7936\n",
            "Epoch 262/300\n",
            "10/10 [==============================] - 1s 51ms/step - loss: 0.0251 - accuracy: 0.7936\n",
            "Epoch 263/300\n",
            "10/10 [==============================] - 1s 51ms/step - loss: 0.0241 - accuracy: 0.7936\n",
            "Epoch 264/300\n",
            "10/10 [==============================] - 1s 52ms/step - loss: 0.0234 - accuracy: 0.7936\n",
            "Epoch 265/300\n",
            "10/10 [==============================] - 1s 50ms/step - loss: 0.0231 - accuracy: 0.7936\n",
            "Epoch 266/300\n",
            "10/10 [==============================] - 1s 51ms/step - loss: 0.0228 - accuracy: 0.7936\n",
            "Epoch 267/300\n",
            "10/10 [==============================] - 1s 52ms/step - loss: 0.0224 - accuracy: 0.7936\n",
            "Epoch 268/300\n",
            "10/10 [==============================] - 1s 52ms/step - loss: 0.0222 - accuracy: 0.7945\n",
            "Epoch 269/300\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.0215 - accuracy: 0.7945\n",
            "Epoch 270/300\n",
            "10/10 [==============================] - 1s 51ms/step - loss: 0.0214 - accuracy: 0.7927\n",
            "Epoch 271/300\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.0214 - accuracy: 0.7945\n",
            "Epoch 272/300\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.0211 - accuracy: 0.7936\n",
            "Epoch 273/300\n",
            "10/10 [==============================] - 1s 52ms/step - loss: 0.0210 - accuracy: 0.7945\n",
            "Epoch 274/300\n",
            "10/10 [==============================] - 1s 51ms/step - loss: 0.0203 - accuracy: 0.7936\n",
            "Epoch 275/300\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.0203 - accuracy: 0.7945\n",
            "Epoch 276/300\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.0198 - accuracy: 0.7945\n",
            "Epoch 277/300\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.0200 - accuracy: 0.7927\n",
            "Epoch 278/300\n",
            "10/10 [==============================] - 1s 51ms/step - loss: 0.0199 - accuracy: 0.7945\n",
            "Epoch 279/300\n",
            "10/10 [==============================] - 1s 52ms/step - loss: 0.0193 - accuracy: 0.7927\n",
            "Epoch 280/300\n",
            "10/10 [==============================] - 1s 52ms/step - loss: 0.0199 - accuracy: 0.7945\n",
            "Epoch 281/300\n",
            "10/10 [==============================] - 1s 51ms/step - loss: 0.0188 - accuracy: 0.7936\n",
            "Epoch 282/300\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.0192 - accuracy: 0.7927\n",
            "Epoch 283/300\n",
            "10/10 [==============================] - 1s 51ms/step - loss: 0.0190 - accuracy: 0.7945\n",
            "Epoch 284/300\n",
            "10/10 [==============================] - 1s 52ms/step - loss: 0.0185 - accuracy: 0.7945\n",
            "Epoch 285/300\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.0187 - accuracy: 0.7927\n",
            "Epoch 286/300\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.0184 - accuracy: 0.7945\n",
            "Epoch 287/300\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.0184 - accuracy: 0.7945\n",
            "Epoch 288/300\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.0182 - accuracy: 0.7927\n",
            "Epoch 289/300\n",
            "10/10 [==============================] - 1s 52ms/step - loss: 0.0183 - accuracy: 0.7945\n",
            "Epoch 290/300\n",
            "10/10 [==============================] - 1s 51ms/step - loss: 0.0178 - accuracy: 0.7936\n",
            "Epoch 291/300\n",
            "10/10 [==============================] - 1s 51ms/step - loss: 0.0179 - accuracy: 0.7936\n",
            "Epoch 292/300\n",
            "10/10 [==============================] - 1s 50ms/step - loss: 0.0178 - accuracy: 0.7945\n",
            "Epoch 293/300\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.0177 - accuracy: 0.7936\n",
            "Epoch 294/300\n",
            "10/10 [==============================] - 1s 51ms/step - loss: 0.0175 - accuracy: 0.7945\n",
            "Epoch 295/300\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.0174 - accuracy: 0.7936\n",
            "Epoch 296/300\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 0.0177 - accuracy: 0.7945\n",
            "Epoch 297/300\n",
            "10/10 [==============================] - 1s 51ms/step - loss: 0.0171 - accuracy: 0.7927\n",
            "Epoch 298/300\n",
            "10/10 [==============================] - 1s 52ms/step - loss: 0.0180 - accuracy: 0.7945\n",
            "Epoch 299/300\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.0167 - accuracy: 0.7945\n",
            "Epoch 300/300\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.0176 - accuracy: 0.7927\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fe223cf6e90>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qx3a18RG-QvQ"
      },
      "source": [
        "# encoder模型和訓練相同\n",
        "encoder_model = Model(encoder_inputs, [encoder_state_h1, encoder_state_c1, encoder_state_h2, encoder_state_c2])\n",
        "\n",
        "# 預測模型中的decoder的初始化狀態需要傳入新的狀態\n",
        "decoder_state_input_h1 = Input(shape=(HIDDEN_SIZE,))\n",
        "decoder_state_input_c1 = Input(shape=(HIDDEN_SIZE,))\n",
        "decoder_state_input_h2 = Input(shape=(HIDDEN_SIZE,))\n",
        "decoder_state_input_c2 = Input(shape=(HIDDEN_SIZE,))\n",
        "\n",
        "# 使用傳入的值來初始化當前模型的輸入狀態\n",
        "decoder_h1, state_h1, state_c1 = lstm1(decoder_inputs, initial_state=[decoder_state_input_h1, decoder_state_input_c1])\n",
        "decoder_h2, state_h2, state_c2 = lstm2(decoder_h1, initial_state=[decoder_state_input_h2, decoder_state_input_c2])\n",
        "decoder_outputs = decoder_dense(decoder_h2)\n",
        "\n",
        "decoder_model = Model([decoder_inputs, decoder_state_input_h1, decoder_state_input_c1, decoder_state_input_h2, decoder_state_input_c2], \n",
        "                      [decoder_outputs, state_h1, state_c1, state_h2, state_c2])"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nB0cJzjM-Wa3",
        "outputId": "9f369f5e-402f-49b8-a38e-74ab12b7788a"
      },
      "source": [
        "TestPath = '/content/drive/MyDrive/Colab Notebooks/translation2019zh_valid.json'\n",
        "for k in range(0,50):\n",
        "    test_data = encoder_input_data[k:k+1]\n",
        "    A1, B1, A2, B2 = encoder_model.predict(test_data)\n",
        "    target_seq = np.zeros((1, 1, CH_VOCAB_SIZE))\n",
        "    target_seq[0, 0, ch2id['\\t']] = 1\n",
        "    outputs = []\n",
        "    while True:\n",
        "        output_tokens, A1, B1, A2, B2 = decoder_model.predict([target_seq, A1, B1, A2, B2])\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        outputs.append(sampled_token_index)\n",
        "        target_seq = np.zeros((1, 1, CH_VOCAB_SIZE))\n",
        "        target_seq[0, 0, sampled_token_index] = 1\n",
        "        if sampled_token_index == ch2id['。']: break\n",
        "        # if len(outputs) > 11: break\n",
        "    \n",
        "    print(en_data[k])\n",
        "    print(''.join([id2ch[i] for i in outputs]))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Look at these coasters over here.\n",
            "看看这边的杯垫。\n",
            "Choose a recorder.\n",
            "选择一个记录员.。\n",
            "I hadn't paid the telephone bill.\n",
            "我还没交电话费。\n",
            "That's easier said than done, of course.\n",
            "当然，知易行难。\n",
            "Side-to-Side Movements.\n",
            "侧向运动。\n",
            "about like 80 degrees.\n",
            "大概华氏80度吧。\n",
            "We all are from Shandong.\n",
            "俺都是山东人。\n",
            "She was possessed by a devil.\n",
            "她着了魔。\n",
            "This wool knits up well.\n",
            "这种毛线很好织。\n",
            "The majority was wrong last time.\n",
            "方是错的。\n",
            "Stone Soup Stories to Go!\n",
            "石头汤（故事去！）。\n",
            "Done. See you tomorrow.\n",
            "一言为定。\n",
            "He eased some of the strains on the poor.\n",
            "缓解了穷人的压力。\n",
            "Could it be that it was written wrongly?\n",
            "莫非写错了?。\n",
            "What a terrible temper!\n",
            "脾气真够坏的！。\n",
            "Great talents flower late.\n",
            "大器晚成。\n",
            "I forbid you to make a sortie today.\n",
            "你今天不许出击。\n",
            "C：My surname is Jiang.\n",
            "C：我姓姜。\n",
            "Well, if it was greater .\n",
            "如果拉力很大。\n",
            "They looked over to the left.\n",
            "她们朝左边看。\n",
            "To supervise the management of printing industry.\n",
            "监督管理印刷业。\n",
            "no one else can see you shake your head.\n",
            "没人看的见你摇头。\n",
            "All photos dials.\n",
            "所有照片刻盘。\n",
            "Stained glass window panels;\n",
            "彩色玻璃窗板；。\n",
            "The murderer was caught red-handed.\n",
            "凶犯当场被抓住。\n",
            "You don’t love Melanie.\n",
            "你是不爱梅兰妮的。\n",
            "His style is very lucid .\n",
            "他的文体很明畅。\n",
            "At this time, there was a male cat.\n",
            "这次是一只小公猫。\n",
            "The truth has leaked out.\n",
            "事实真相已泄露。\n",
            "Material evidence must also be original.\n",
            "物证应当提交原物。\n",
            "The brother and sister quickly ran.\n",
            "兄妹俩快步的跑着。\n",
            "The ship doubled Cape Horn .\n",
            "那船绕过合恩角。\n",
            "Consider your audience.\n",
            "考虑你的听众。\n",
            "Two times five is ten.\n",
            "二乘五等于一十。\n",
            "Erhai Lake （in Yunnan Province）\n",
            "洱海。\n",
            "He is a junior it?\n",
            "他是一个初中生吗？。\n",
            "I locked all the doors.\n",
            "我锁好了所有的门。\n",
            "Problems, if any, should be solved without delay.\n",
            "有问题要及时解决。\n",
            "This is a big deal!\n",
            "这可是件大事儿啊！。\n",
            "I need some water to quench .\n",
            "我想要些水解渴。\n",
            "Helen:Hot springs in Iceland?\n",
            "海伦：冰岛有温泉？。\n",
            "Which hole is this?\n",
            "这是几杆洞？。\n",
            "The producer was Lawan Davis.\n",
            "生产者蜡丸戴维斯。\n",
            "Cuddle with your kids.\n",
            "拥抱你的孩子。\n",
            "It included in it thousands of brackets.\n",
            "里面有上千个托座。\n",
            "Deals for approval by admin.\n",
            "交易由管理员批准。\n",
            "Um, not so good.\n",
            "嗯，这并不太妙。\n",
            "Can ferrets get fleas?\n",
            "雪貂会不会生跳蚤？。\n",
            "F: Lubanga is in The Hague.\n",
            "F：在海牙。\n",
            "No definite article.\n",
            "没有定冠词。\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}